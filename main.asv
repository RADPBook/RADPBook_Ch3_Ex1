% Main Script

PsiPsi = [];
PsiU = [];
Phi = [];
CostQ = [];
x_save = []; % Keep track of the states
t_save = []; % Keep track of the time

currentTime = 0; % Indicating the current time throught the simulation

PhiLength = numel(Phi_fun(zeros(1,4)));
PsiLength = numel(Psi_fun(zeros(1,4)));

r = 1;  % Weight on u

N = min(80,2*(PsiLength+PsiLength));
IterMax = 20;  % Number of iterations

X = [0.1,-5,0.2,2,zeros(1,PsiLength^2+PsiLength+1)];

T = 0.01; % Length for each time interval

%% Online Data Collection
for i = 1:N	
	[t,X] = ode45(@adpSysWrapper, ...
		          [i-1,i]*T, ...
				  [X(end,1:4) zeros(1, PsiLength^2 + PsiLength + 1)]);
	Phi    = [Phi; 
		      Phi_fun(X(end,1:4))-Phi_fun(X(1,1:4))];        %#ok<AGROW>
	PsiPsi = [PsiPsi;
		      X(end,4 + (1:PsiLength^2))];                   %#ok<AGROW>
	PsiU   = [PsiU; 
		      X(end,4 + PsiLength^2 + (1:PsiLength))];       %#ok<AGROW>
	CostQ = [CostQ; 
		      X(end,end)];			                         %#ok<AGROW>
    t_save = [t_save; 
              t(:)];                                         %#ok<AGROW>
    x_save = [x_save; 
              X(:,1:4)];                                     %#ok<AGROW>
    currentTime = t_save(end);
end

% Off-Policy Learning. Solve the matrix A*pw = B 

w = zeros(PsiLength,1);

for i = 1:IterMax
	A = [Phi -2*r*PsiU-2*r*PsiPsi*kron(w,eye(PsiLength))];
    B = -(CostQ + PsiPsi*kron(w,w));
	pw = A\B;
  	p = pw(1:PhiLength);
	w = pw(PhiLength+1:end);
end

%% Post learning
% Terminate exploration noise but keep appying the inital gains until the 
% states enters the region of attraction

% Compute the region of attraction
D = getRegionOfAttraction(p);
% Keep checking if state is in the region of attraction
currentStates = x_save(end,:);
while  ~isInRegionOfAttraction(currentStates,p,D);
	[t,y] = ode45(@(t,x) simpleSysWrapper(t,x,w*0), ...
                                        currentTime+[0,0.1], ...
                                        currentStates);
     t_save = [t_save; t];
	 x_save = [x_save; y];
	 currentStates = x_save(end,:);	 
	 currentTime = t_save(end);
end

%% Update controller and finish the rest of the simulation
[t,y] = ode45(@(t,x) simpleSysWrapper(t,x,-w), ...
              currentTime+[0,5], ...
              currentStates);
t_save = [t_save
          t(:)];
x_save = [x_save
          y(:,1:4)];

% Also compare with unlearned performance
[t0,y0] = ode45(@(t,x) simpleSysWrapper(t,x,w*0), ...
                                        currentTime+[0,5], ...
                                        currentStates);

%% Plotting results
figure(1)
subplot(221)
plot(t_save,x_save(:,1),t0, y0(:,1), 'r--', 'LineWidth', 2)
xlabel('Time (sec)')
legend('x_b (Under ADP)', 'x_b (Unlearned)')
%
subplot(222)
plot(t_save,x_save(:,2),t0, y0(:,2), 'r--', 'LineWidth', 2)
xlabel('Time (sec)')
legend('x_b (Under ADP)', 'x_b (Unlearned)')
%
subplot(223)
plot(t_save,x_save(:,3),t0, y0(:,3), 'r--', 'LineWidth', 2)
xlabel('Time (sec)')
legend('x_b (Under ADP)', 'x_b (Unlearned)')
%
subplot(224)
plot(t_save,x_save(:,4),t0, y0(:,4), 'r--', 'LineWidth', 2)
xlabel('Time (sec)')
legend('x_b (Under ADP)', 'x_b (Unlearned)')

%%
%plot(tt,yy(:,2),tt0,yy0(:,2))
%legend('learned', 'unlearned')


%% Clean up
save simResults.mat 

clear A D Phi PsiPsi X r t_save y B IterMax PhiLength PsiU currentStates  p              t              w              y0             
CostQ          N              PsiLength      T              currentTime    pw             t0             x_save      

